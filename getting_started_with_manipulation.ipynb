{"cells":[{"cell_type":"markdown","source":["#The slippery slope of XAI evaluation\n","\n","This notebook illustrates how the lack of ground truth explanations allows for manipulation of quantitative evaluation in explainable artificial intelligence (XAI). If you are running this notebook on Google Colab, remember to enable GPU support to speed up computation.\n","\n","This example illustrates the basic concept on the MNIST dataset, where we optimize across a feasible set of perturbation functions to find a set of hyperparameters that give the best performance for a focus method.\n"],"metadata":{"id":"KSDlBXJUneR5"}},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"zU7GYaVJuc6S","executionInfo":{"status":"ok","timestamp":1725620681875,"user_tz":-120,"elapsed":18748,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"outputs":[],"source":["#@title install packages\n","\n","!pip install captum\n","!pip install quantus\n","\n","from IPython.display import clear_output\n","\n","clear_output()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"i3chytRNqx33","cellView":"form","executionInfo":{"status":"ok","timestamp":1725620708794,"user_tz":-120,"elapsed":26921,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"outputs":[],"source":["#@title load packages\n","\n","import torch\n","import quantus\n","import torchvision\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"spCaefBNq8mX","cellView":"form","executionInfo":{"status":"ok","timestamp":1725620715845,"user_tz":-120,"elapsed":7055,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"outputs":[],"source":["#@title Download data and create dataset and dataloader\n","\n","device = 'cuda'\n","BATCH_SIZE = 500\n","\n","transformer = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","train_set = torchvision.datasets.MNIST(root='./sample_data', train=True, transform=transformer, download=True)\n","test_set = torchvision.datasets.MNIST(root='./sample_data', train=False, transform=transformer, download=True)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, pin_memory=True)\n","\n","clear_output()"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"RPYoMAPnvyvn","executionInfo":{"status":"ok","timestamp":1725620715845,"user_tz":-120,"elapsed":4,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"outputs":[],"source":["#@title Define the classification network and initialize network\n","\n","class LeNet(torch.nn.Module):\n","    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n","        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n","        self.relu_1 = torch.nn.ReLU()\n","        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n","        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n","        self.relu_2 = torch.nn.ReLU()\n","        self.fc_1 = torch.nn.Linear(256, 120)\n","        self.relu_3 = torch.nn.ReLU()\n","        self.fc_2 = torch.nn.Linear(120, 84)\n","        self.relu_4 = torch.nn.ReLU()\n","        self.fc_3 = torch.nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool_1(self.relu_1(self.conv_1(x)))\n","        x = self.pool_2(self.relu_2(self.conv_2(x)))\n","        x = x.view(x.shape[0], -1)\n","        x = self.relu_3(self.fc_1(x))\n","        x = self.relu_4(self.fc_2(x))\n","        x = self.fc_3(x)\n","        return x\n","\n","    def softmax_forward(self, x):\n","        x = x.unsqueeze(0)\n","        return torch.nn.functional.softmax(self.forward(x), dim=1)\n","\n","model = LeNet()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","id":"OX2X3f9qvuCR","executionInfo":{"status":"ok","timestamp":1725620715845,"user_tz":-120,"elapsed":4,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"outputs":[],"source":["#@title Define functions for training and evaluation\n","\n","import torchvision\n","\n","def train_model(model,\n","                train_data: torchvision.datasets,\n","                test_data: torchvision.datasets,\n","                device: torch.device,\n","                epochs: int = 20,\n","                criterion: torch.nn = torch.nn.CrossEntropyLoss(),\n","                optimizer: torch.optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n","                evaluate: bool = False):\n","    \"\"\"Train torch model.\"\"\"\n","\n","    model.train()\n","\n","    for epoch in range(epochs):\n","\n","        for images, labels in train_data:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            logits = model(images)\n","            loss = criterion(logits, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Evaluate model!\n","        if evaluate:\n","            predictions, labels = evaluate_model(model, test_data, device)\n","            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n","\n","        print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n","\n","    return model\n","\n","def evaluate_model(model, data, device):\n","    \"\"\"Evaluate torch model.\"\"\"\n","    model.eval()\n","    logits = torch.Tensor().to(device)\n","    targets = torch.LongTensor().to(device)\n","\n","    with torch.no_grad():\n","        for images, labels in data:\n","            images, labels = images.to(device), labels.to(device)\n","            logits = torch.cat([logits, model(images)])\n","            targets = torch.cat([targets, labels])\n","\n","    return torch.nn.functional.softmax(logits, dim=1), targets"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"ho8Vfeg4vzyd","executionInfo":{"status":"ok","timestamp":1725620814406,"user_tz":-120,"elapsed":98564,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}},"outputId":"a5ce5571-38d1-4ceb-a383-166e06ee190c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - test accuracy: 19.62% and CE loss 2.28\n","Epoch 2/10 - test accuracy: 85.77% and CE loss 0.48\n","Epoch 3/10 - test accuracy: 93.39% and CE loss 0.25\n","Epoch 4/10 - test accuracy: 95.26% and CE loss 0.21\n","Epoch 5/10 - test accuracy: 96.49% and CE loss 0.19\n","Epoch 6/10 - test accuracy: 96.80% and CE loss 0.09\n","Epoch 7/10 - test accuracy: 97.38% and CE loss 0.07\n","Epoch 8/10 - test accuracy: 97.69% and CE loss 0.06\n","Epoch 9/10 - test accuracy: 97.62% and CE loss 0.10\n","Epoch 10/10 - test accuracy: 97.98% and CE loss 0.06\n","Model test accuracy: 97.98%\n"]}],"source":["#@title Train and evaluate model\n","\n","model = train_model(model=model.to(device),\n","                    train_data=train_loader,\n","                    test_data=test_loader,\n","                    device=device,\n","                    epochs=10,\n","                    criterion=torch.nn.CrossEntropyLoss().to(device),\n","                    optimizer=torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9),\n","                    evaluate=True)\n","\n","# Model to GPU and eval mode.\n","model.to(device)\n","model.eval()\n","\n","# Check test set performance.\n","predictions, labels = evaluate_model(model, test_loader, device)\n","test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n","print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"]},{"cell_type":"code","source":["#@title Function for creating faithfulness curve\n","\n","from quantus import gaussian_noise, uniform_noise, baseline_replacement_by_blur\n","\n","def perturb_input(x, perturbation_index, perturbation_function):\n","    if perturbation_function == 'baseline_replacement_by_blur':\n","        x = baseline_replacement_by_blur(x, perturbation_index, [0], blur_kernel_size=7)\n","    elif perturbation_function == 'gaussian_noise':\n","        x = gaussian_noise(x, perturbation_index, [0], perturb_std=1.0)\n","    elif perturbation_function == 'uniform_noise':\n","        x = uniform_noise(x, perturbation_index, [0], lower_bound=-1.0, upper_bound=1.0)\n","    else:\n","        raise ValueError('Unknown perturbation function')\n","    return x\n","\n","def create_faithfulness_curve(model, x_sample, a_sample, subset_size, perturbation_function):\n","\n","  model.eval()\n","  _, H, W = x_sample.shape\n","  number_of_pixels = H*W\n","  number_of_subsets = number_of_pixels // subset_size\n","\n","  a_sample = a_sample.flatten()\n","  sorted_idx = np.argsort(-a_sample)\n","\n","  x_perturbed = x_sample.copy()\n","\n","  initial_prediction_scores = torch.nn.functional.softmax(model(torch.tensor(x_perturbed, device='cuda').unsqueeze(0)), dim=1)\n","  initial_prediction_index = initial_prediction_scores.argmax()\n","\n","  faithfulness_curve = []\n","\n","  for subset_i in range(number_of_subsets):\n","\n","      x_perturbed = x_perturbed.flatten()\n","      pert_idx = sorted_idx[subset_i*subset_size:(subset_i+1)*subset_size]\n","      x_perturbed = perturb_input(x_perturbed.flatten(), pert_idx, perturbation_function)\n","      x_perturbed = x_perturbed.reshape(1, 28, 28)\n","\n","      prediction_scores = torch.nn.functional.softmax(model(torch.tensor(x_perturbed, device='cuda').unsqueeze(0)), dim=1).squeeze()\n","\n","      faithfulness_curve.append(prediction_scores[initial_prediction_index].item())\n","\n","  return faithfulness_curve\n"],"metadata":{"id":"ZxK-VWxPx3PP","executionInfo":{"status":"ok","timestamp":1725623138304,"user_tz":-120,"elapsed":303,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["#@title Calculate faithfulness score across several XAI methods for different partition size\n","\n","\n","xai_methods = ['Saliency', 'LRP', 'KernelShap']\n","partition_size = 28\n","image_size = 28\n","number_of_channels = 1\n","number_of_analysis_samples = 100\n","feasible_set_of_perturbation_functions = ['gaussian_noise', 'uniform_noise', 'baseline_replacement_by_blur']\n","results = pd.DataFrame(index=xai_methods, columns=feasible_set_of_perturbation_functions)\n","\n","analysis_set, _ = torch.utils.data.random_split(test_set, [number_of_analysis_samples, len(test_set)-number_of_analysis_samples])\n","analysis_loader = torch.utils.data.DataLoader(analysis_set, batch_size=number_of_analysis_samples, shuffle=False)\n","\n","for perturbation_function in feasible_set_of_perturbation_functions:\n","    for xai_method in xai_methods:\n","\n","        faithfulness_scores = []\n","\n","        for x_batch, y_batch in analysis_loader:\n","            x_batch , y_batch = x_batch.to('cuda'), y_batch.to('cuda')\n","            a_batch = quantus.explain(model, x_batch, y_batch, method=xai_method,\n","                                      img_size=image_size, nr_channels=number_of_channels, normalise=False)\n","\n","            with torch.no_grad():\n","                for idx, (x_in, a_in) in enumerate(zip(x_batch, a_batch)):\n","\n","                    faithfulness_curve = create_faithfulness_curve(model, x_in.numpy(force=True), a_in, partition_size, perturbation_function)\n","                    faithfulness_scores.append(np.trapz(faithfulness_curve))\n","\n","        results.at[xai_method, perturbation_function] = np.mean(faithfulness_scores)\n","        print(perturbation_function, xai_method)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eq05mQX1vJt5","executionInfo":{"status":"ok","timestamp":1725624193621,"user_tz":-120,"elapsed":63192,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}},"outputId":"c4f43c4b-f8c2-44a8-8c5b-09c3a8d41eaf"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["gaussian_noise Saliency\n","gaussian_noise LRP\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/attr/_core/lime.py:1109: UserWarning: You are providing multiple inputs for Lime / Kernel SHAP attributions. This trains a separate interpretable model for each example, which can be time consuming. It is recommended to compute attributions for one example at a time.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["gaussian_noise KernelShap\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["uniform_noise Saliency\n","uniform_noise LRP\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/attr/_core/lime.py:1109: UserWarning: You are providing multiple inputs for Lime / Kernel SHAP attributions. This trains a separate interpretable model for each example, which can be time consuming. It is recommended to compute attributions for one example at a time.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["uniform_noise KernelShap\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["baseline_replacement_by_blur Saliency\n","baseline_replacement_by_blur LRP\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/captum/attr/_core/lime.py:1109: UserWarning: You are providing multiple inputs for Lime / Kernel SHAP attributions. This trains a separate interpretable model for each example, which can be time consuming. It is recommended to compute attributions for one example at a time.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["baseline_replacement_by_blur KernelShap\n"]}]},{"cell_type":"markdown","source":["#Manipulation output\n","\n","The cell below calculates the scores for the different partition sizes. We assume that a partion size of 14 is the base option, as this is commonly used in the literature. Our manipulation is towards LRP, so we seek to optimize towards LRP. Note that since we are calculating the AUC of the faithfulness curve, we are looking for the minimal value.\n"],"metadata":{"id":"BD_s2OAWBgp3"}},{"cell_type":"code","source":["#@title calculate maipulation scores and print base versus manipulated hyperparameters\n","\n","focus_method = 'LRP'\n","non_focus_methods = ['Saliency', 'KernelShap']\n","\n","print(f\"Base option scores \\n {results['uniform_noise']}\")\n","print(f\"Top method base option {results['uniform_noise'].idxmin()}\")\n","\n","adversarial_objective = pd.DataFrame(index=[focus_method], columns=feasible_set_of_perturbation_functions)\n","\n","for perturbation_function in feasible_set_of_perturbation_functions:\n","\n","    adversarial_objective.at[focus_method, perturbation_function] = results[perturbation_function][focus_method]-np.mean(results[perturbation_function][non_focus_methods])\n","\n","\n","top_perturbation_function_for_focus_method = adversarial_objective.idxmin(axis=1).values[0]\n","\n","print(f\"Manipulated option scores \\n {results[top_perturbation_function_for_focus_method]}\")\n","print(f\"Top method base option {results[top_perturbation_function_for_focus_method].idxmin()}\")"],"metadata":{"id":"nb6GST1z4U_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725624248262,"user_tz":-120,"elapsed":269,"user":{"displayName":"Kristoffer Wickstrøm","userId":"04547063320981780474"}},"outputId":"99cbe15a-902e-4c9b-9a81-b1d8d8e7af5d"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Base option scores \n"," Saliency      23.277109\n","LRP           24.828824\n","KernelShap    24.425446\n","Name: uniform_noise, dtype: object\n","Top method base option Saliency\n","Manipulated option scores \n"," Saliency       22.31418\n","LRP           19.626559\n","KernelShap    24.195569\n","Name: baseline_replacement_by_blur, dtype: object\n","Top method base option LRP\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyM+ZPO2CYScLHTiB0jzFmuv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}